# ============================================================================
# AI VOICE AGENT - ENVIRONMENT CONFIGURATION
# ============================================================================
# Copy this file to .env and fill in your values
# DO NOT commit .env to version control (already in .gitignore)
# ============================================================================

# ============================================================================
# API KEYS
# ============================================================================

# Google Gemini API Key (Required for LLM chat features)
# Get your key from: https://makersuite.google.com/app/apikey
GEMINI_API_KEY=

# ============================================================================
# PIPER TTS CONFIGURATION
# ============================================================================

# Path to Piper executable (Windows binary)
# Default: piper_windows_amd64/piper/piper.exe (relative to project root)
PIPER_EXE_PATH=piper_windows_amd64/piper/piper.exe

# Path to Piper ONNX model file
# Default: piper_windows_amd64/piper/models/en_US-lessac-medium.onnx
PIPER_MODEL_PATH=piper_windows_amd64/piper/models/en_US-lessac-medium.onnx

# ============================================================================
# WHISPER STT CONFIGURATION
# ============================================================================

# Whisper model size: tiny, base, small, medium, large
# Smaller = faster but less accurate, Larger = slower but more accurate
# Recommended for CPU: tiny or base
WHISPER_MODEL_NAME=tiny

# Whisper compute type: int8, float16, float32
# int8 = fastest, lowest memory, good for CPU
# float32 = slowest, highest accuracy
WHISPER_COMPUTE_TYPE=int8

# Number of CPU threads for Whisper inference
WHISPER_CPU_THREADS=4

# ============================================================================
# SERVER CONFIGURATION
# ============================================================================

# Backend server host (0.0.0.0 = all interfaces, 127.0.0.1 = localhost only)
BACKEND_HOST=0.0.0.0

# Backend server port
BACKEND_PORT=8000

# Streamlit UI port
STREAMLIT_PORT=8501

# ============================================================================
# SYSTEM PROMPT (LLM)
# ============================================================================

# System prompt for AI assistant (optional - has sensible default)
# SYSTEM_PROMPT=You are a helpful AI voice assistant. Answer questions clearly and concisely.

# ============================================================================
# LOGGING
# ============================================================================

# Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# ============================================================================
# NOTES
# ============================================================================
#
# After editing this file:
# 1. Save as .env (not .env.example)
# 2. Fill in your GEMINI_API_KEY
# 3. Verify PIPER_EXE_PATH and PIPER_MODEL_PATH match your installation
# 4. Run: python backend.py
#
# ============================================================================
